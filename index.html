<!DOCTYPE HTML>
<html>

<head>
  <title>Xin Jin's Home Page 金鑫-个人主页</title>
  <meta name="description" content="website description" />
  <meta name="keywords" content="website keywords, website keywords" />
  <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
  <link rel="stylesheet" type="text/css" href="css/style.css" />
  <!-- modernizr enables HTML5 elements and feature detects -->
  <script type="text/javascript" src="js/modernizr-1.5.min.js"></script>
</head>

<body>
	<a name="top"></a>
  <div id="main">
    <header>
      <div id="logo"><h1>Xin Jin </h1></div>
      <nav>
        <ul class="lavaLampWithImage" id="lava_menu">
          <li class="current"><a href="index.html">Home</a></li>
          <li><a href="#publications">Publications</a></li>

        </ul>
      </nav>
    </header>
    <div id="site_content">
      <ul class="slideshow">
        <li class="show"><img width="950" height="140" src="images/1.jpg" alt="&quot; &quot;" /></li>
        <li><img width="950" height="140" src="images/2.jpg" alt="&quot; &quot;" /></li>
        <li><img width="950" height="140" src="images/3.jpg" alt="&quot; &quot;" /></li>
      </ul>
      <div id="sidebar_container">
        
        <div class="sidebar">
          <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="#publications">Publications</a></li>

          </ul>
        </div>
      </div>
      
      
      <div id="content">
      <!-- begin of main content, except header and the top picture -->
      	      
        <h2>Xin Jin <font face="楷体, 华文中宋, 华文隶书, 黑体, 仿宋, 方正姚体" size="5.5"><b>金鑫</b></font> </h2>
        

     <br><br>
        <font face="Times New Roman" size="4">Ph.D. Candidate<br>Key Laboratory of Intelligent Information Processing,

          <br><a href="http://www.ict.ac.cn/" target="_balnk">Institute of 
            Computing Technology,</a><br>
            <a href="http://www.cas.ac.cn/" target="_balnk">Chinese 
            Academy of Sciences (CAS)</a><br>No.6 Kexueyuan South Road 
          Zhongguancun,<br>Haidian District Beijing, China<br><br>
          <b>Tel: </b>(+8610) 
          6260-0506<br>
          <b>Homepage: </b><a href="http://www.intsci.ac.cn/users/jinxin">http://www.intsci.ac.cn/users/jinxin</a><br>
          <b>Email: 
            </b>jinx at ics.ict.ac.cn<br>
        </font></p></td>
    <td halign="right" valign="top" width="1%">
</div>
      
      <div id="site_content">
      
          <!-- Xin Jin's publications -->    
    <a name="publications"></a>
           <h2>Publications</h2> 
       
       <h3>Conference Papers</h3>
       
       <ul>
            <li><font face="Times New Roman"><b>Xin Jin</b>, Fuzhen Zhuang, Shuhui Wang, Qing He and Zhongzhi Shi. <strong>Shared Structure Learning for Multiple Tasks with Multiple Views</strong>. 
            	<em>European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD 2013)</em>, Prague, Czech Republic, Sep 23 - 27, 2013. <a href="Mypapers/ECML13_JinXin.pdf" target="_balnk">(<font color=blue>PDF</font>)</a>
            	  <a href="ECML_13_codes.html" target="_balnk">(<font color=blue>Source Code</font>)</a> (EI)
            	<br>  <br>    </font>
            </li>
        </ul>
       
       <h3>Journal Papers</h3>
       <ul>
        <li><font face="Times New Roman">Qing He, <b>Xin Jin</b>, Changying Du, Fuzhen Zhuang and Zhongzhi Shi. <strong>Clustering in Extreme Learning Machine Feature Space</strong>. <i>Neurocomputing</i>, (128), pp. 88-95, 2014. <a href="Mypapers/ELM-Neurocomputing-2013.pdf" target="_balnk">(<font color=blue>PDF</font>)</a> <a href="Mypapers/sample_code_for_ELM_clustering_2013.rar" target="_balnk">(<font color=blue>Source Code</font>)</a> (SCI, EI)
         	<br> </font>
  			 </li>
  			  <br>
  			 <li><font face="Times New Roman"><b>Xin Jin</b>, Yongquan Liang, Dongping Tian and Fuzhen Zhuang. <strong>Particle swarm optimization using dimension selection methods</strong>. <i>Applied Mathematics and Computation,</i> (219), pp. 5185–5197, 2013. <a href="Mypapers/PSO_dimension_selection_2013.pdf" target="_balnk">(<font color=blue>PDF</font>)</a> (SCI, EI)
         	<br>  </font>
  			 </li> <br>
  			 
      </ul>
      
      <h2>Useful Links</h2>
        <ul>
        <li>ICML: <a href="http://icml.cc/2014">(2014)</a> <a href="http://icml.cc/2013/">(2013)</a></li>
        <li>NIPS: <a href="http://nips.cc/Conferences/2012/">(2012)</a></li>
        <li>SIGKDD: <a href="http://www.kdd.org/kdd2014">(2014)</a> <a href="http://www.kdd.org/kdd2013">(2013)</a></li>
        <li>ECML-PKDD: <a href="http://http://www.ecmlpkdd2013.org/">(2013)</a></li>
        <li>UAI: <a href="http://www.auai.org/uai2014/">(2014)</a> <a href="http://www.auai.org/uai2013/">(2013)</a></li>
        <li>IJCAI: <a href="http://www.ezconf.net/ijcai13/">(2013)</a></li>
        <li>AAAI: <a href="http://www.aaai.org/Conferences/AAAI/aaai14.php">(2014)</a> <a href="http://www.aaai.org/Conferences/AAAI/aaai13.php">(2013)</a></li>
        <li>ICDM: <a href="http://icdm2012.ua.ac.be/">(2012)</a></li>
        <li>SDM: <a href="http://www.siam.org/meetings/sdm14/">(2014)</a> <a href="http://www.siam.org/meetings/sdm13/">(2013)</a></li>
        <li>WSDM: <a href="http://www.wsdm-conference.org/2014/">(2014)</a> <a href="http://www.wsdm2013.org/">(2013)</a></li>
        <li>SIGIR: <a href="http://sigir2013.ie/">(2013)</a></li>
        <li>CIKM: <a href="http://www.fudan.edu.cn/cikm2014">(2014)</a> <a href="http://www.cikm2013.org/">(2013)</a></li>
        <li>WWW: <a href="http://web.geni-pco.com/www2014/">(2014)</a></li>
  			  <br> 			 
      </ul>
      
      <h2>Paper Abstract</h2>
        <ul>
            <li><font face="Times New Roman"><b>Xin Jin</b>, Fuzhen Zhuang, Shuhui Wang, Qing He and Zhongzhi Shi. <strong>Shared Structure Learning for Multiple Tasks with Multiple Views</strong>. 
            	<em>European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD 2013)</em>, Prague, Czech Republic, Sep 23 - 27, 2013. <a href="Mypapers/ECML13_JinXin.pdf" target="_balnk">(<font color=blue>PDF</font>)</a>
            	 </font>
            	 <p> <font face="Times New Roman" size=2 >Real-world problems usually exhibit dual-heterogeneity, i.e.,
every task in the problem has features from multiple views, and multiple
tasks are related with each other through one or more shared views.
To solve these multi-task problems with multiple views, we propose a
shared structure learning framework, which can learn shared predictive
structures on common views from multiple related tasks, and use the consistency
among different views to improve the performance. An alternating
optimization algorithm is derived to solve the proposed framework.
Moreover, the computation load can be dealt with locally in each task
during the optimization, through only sharing some statistics, which significantly
reduces the time complexity and space complexity. Experimental
studies on four real-world data sets demonstrate that our framework
significantly outperforms the state-of-the-art baselines. </font></p>
            </li>
  			  <br> 
  			  <li><font face="Times New Roman">Qing He, <b>Xin Jin</b>, Changying Du, Fuzhen Zhuang and Zhongzhi Shi. <strong>Clustering in Extreme Learning Machine Feature Space</strong>. <i>(Neurocomputing)</i>. <a href="Mypapers/ELM-Neurocomputing-2013.pdf" target="_balnk">(<font color=blue>PDF</font>)</a>(SCI)
         	<br> </font>
         	<p> <font face="Times New Roman" size=2 >
         		Extreme Learning Machine (ELM), used for the “generalized” single-hidden-layer
feedforward networks (SLFNs), is a unified learning platform that can use a widespread
type of feature mappings. In theory, ELM can approximate any target continuous
function and classify any disjoint regions; in application, many experiment
results have already demonstrated the good performance of ELM. In view of the
good properties of the ELM feature mapping, the clustering problem using ELM
feature mapping techniques is studied in this paper. Experiments show that the proposed
ELM kMeans algorithm and ELM NMF (Nonnegative Matrix Factorization)
clustering can get better clustering results than the corresponding Mercer kernel
based methods and the traditional algorithms using the original data. Moreover,
the proposed methods have the advantage of being more convenient to implementation
and computation, as the ELM feature mapping is much simpler than the
Mercer kernel function based feature mapping methods.</font></p>
  			 </li>
  			  <br>
  			 <li><font face="Times New Roman"><b>Xin Jin</b>, Yongquan Liang, Dongping Tian and Fuzhen Zhuang. <strong>Particle swarm optimization using dimension selection methods</strong>. <i>Applied Mathematics and Computation,</i> (219), pp. 5185–5197, 2013. <a href="Mypapers/PSO_dimension_selection_2013.pdf" target="_balnk">(<font color=blue>PDF</font>)</a>(SCI)
         	<br>  </font>
         	<p> <font face="Times New Roman" size=2 >
         		Particle swarm optimization (PSO) has undergone many changes since its introduction in
1995. Being a stochastic algorithm, PSO and its randomness present formidable challenge
for the theoretical analysis of it, and few of the existing PSO improvements have make an
effort to eliminate the random coefficients in the PSO updating formula. This paper analyzes
the importance of the randomness in the PSO, and then gives a PSO variant without
randomness to show that traditional PSO cannot work without randomness. Based on our
analysis of the randomness, another way of using randomness is proposed in PSO with random
dimension selection (PSORDS) algorithm, which utilizes random dimension selection
instead of stochastic coefficients. Finally, deterministic methods to do the dimension selection
are proposed, and the resultant PSO with distance based dimension selection
(PSODDS) algorithm is greatly superior to the traditional PSO and PSO with heuristic
dimension selection (PSOHDS) algorithm is comparable to traditional PSO algorithm. In
addition, using our dimension selection method to a newly proposed modified particle
swarm optimization (MPSO) algorithm also gets improved results. The experiment results
demonstrate that our analysis about the randomness is correct and the usage of deterministic
dimension selection method is very helpful.
         		</font></p>
  			 </li> 			 
      </ul>
      
      
      
      
      <p>&nbsp;</p>
      <p>&nbsp;</p>
      <br>
      <br><br><br><br><br><br>

      </div>
      

    
      <!-- end of main content, except footer -->
      
    </div>
    
    <a href="http://www2.clustrmaps.com/user/09d1108f3"><img src="http://www2.clustrmaps.com/stats/maps-no_clusters/www.intsci.ac.cn-users-jinxin-index.html-thumb.jpg" alt="Locations of visitors to this page" />
</a>

    <footer>
      <p><a href="index.html">Home</a> | <a href="#publications">Publications</a> | <a href="#top">Back to Top</a> </p>
      <p>&copy; 2014 Xin Jin. All Rights Reserved. 
    </footer>
  </div>
  <!-- javascript at the bottom for fast page loading -->
  <script type="text/javascript" src="js/jquery.min.js"></script>
  <script type="text/javascript" src="js/jquery.easing.min.js"></script>
  <script type="text/javascript" src="js/jquery.lavalamp.min.js"></script>
  <script type="text/javascript" src="js/image_fade.js"></script>
  <script type="text/javascript">
    $(function() {
      $("#lava_menu").lavaLamp({
        fx: "backout",
        speed: 700
      });
    });
  </script>
<div style="display:none"><script src='http://v7.cnzz.com/stat.php?id=155540&web_id=155540' language='JavaScript' charset='gb2312'></script></div>
</body>
</html>
